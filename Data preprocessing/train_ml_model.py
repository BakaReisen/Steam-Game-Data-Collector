"""
è®­ç»ƒåœ¨çº¿äººæ•°é¢„æµ‹æ¨¡å‹
åŸºäº Source data.csv ä¸­çš„å®Œæ•´æ•°æ®è®­ç»ƒæ¨¡å‹
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import joblib
import os
from datetime import datetime
import re
import json

class PlayerCountPredictor:
    def __init__(self):
        """åˆå§‹åŒ–é¢„æµ‹å™¨"""
        self.models = {}
        self.feature_importance = {}
        self.training_stats = {}
        
    def extract_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ä»æ•°æ®ä¸­æå–ç‰¹å¾
        
        Args:
            df: åŸå§‹æ•°æ®
            
        Returns:
            ç‰¹å¾DataFrame
        """
        features = pd.DataFrame()
        
        # 1. æ¸¸æˆå¹´é¾„(ä»å‘è¡Œæ—¥æœŸè®¡ç®—)
        def calculate_game_age(date_str):
            if pd.isna(date_str) or date_str in ['N/A', 'Coming Soon', 'TBA', '']:
                return -1
            try:
                year_match = re.search(r'(\d{4})', str(date_str))
                if year_match:
                    release_year = int(year_match.group(1))
                    current_year = datetime.now().year
                    return max(0, current_year - release_year)
            except:
                pass
            return -1
        
        features['game_age_years'] = df['å‘è¡Œæ—¥æœŸ'].apply(calculate_game_age)
        
        # 2. æ˜¯å¦å…è´¹æ¸¸æˆ
        features['is_free'] = df['æ ¼å¼åŒ–ä»·æ ¼'].apply(
            lambda x: 1 if pd.notna(x) and str(x).lower() in ['free', 'å…è´¹'] else 0
        )
        
        # 3. ä»·æ ¼(æ•°å€¼åŒ–)
        def extract_price(price_str):
            if pd.isna(price_str) or str(price_str).lower() in ['free', 'å…è´¹', 'n/a', '']:
                return 0.0
            try:
                # æå–æ•°å­—
                numbers = re.findall(r'\d+\.?\d*', str(price_str))
                if numbers:
                    return float(numbers[0])
            except:
                pass
            return 0.0
        
        features['price_numeric'] = df['æ ¼å¼åŒ–ä»·æ ¼'].apply(extract_price)
        
        # 4. æ¸¸æˆæ—¶é•¿ç‰¹å¾
        features['playtime_avg'] = pd.to_numeric(df['å¹³å‡æ¸¸æˆæ—¶é•¿(åˆ†é’Ÿ)'], errors='coerce').fillna(0)
        features['playtime_median'] = pd.to_numeric(df['ä¸­ä½æ•°æ¸¸æˆæ—¶é•¿(åˆ†é’Ÿ)'], errors='coerce').fillna(0)
        
        # 5. æ¸¸æˆæ—¶é•¿ä¸ä»·æ ¼æ¯”(æ€§ä»·æ¯”æŒ‡æ ‡)
        features['playtime_price_ratio'] = features.apply(
            lambda row: row['playtime_avg'] / max(row['price_numeric'], 1) if row['price_numeric'] > 0 else row['playtime_avg'],
            axis=1
        )
        
        # 6. åœ¨çº¿äººæ•°ç‰¹å¾(ç”¨äºäº’ç›¸é¢„æµ‹)
        features['current_players'] = pd.to_numeric(df['å½“å‰åœ¨çº¿äººæ•°'], errors='coerce').fillna(0)
        features['peak_24h'] = pd.to_numeric(df['24å°æ—¶å³°å€¼'], errors='coerce').fillna(0)
        features['peak_alltime'] = pd.to_numeric(df['å†å²æœ€é«˜åœ¨çº¿'], errors='coerce').fillna(0)
        
        # 7. è¡ç”Ÿç‰¹å¾
        # æ¸¸æˆæ´»è·ƒåº¦(å½“å‰åœ¨çº¿/24å°æ—¶å³°å€¼)
        features['activity_ratio'] = features.apply(
            lambda row: row['current_players'] / row['peak_24h'] if row['peak_24h'] > 0 else 0,
            axis=1
        )
        
        # å†å²å¢é•¿å€æ•°(å†å²å³°å€¼/24å°æ—¶å³°å€¼)
        features['historical_growth'] = features.apply(
            lambda row: row['peak_alltime'] / row['peak_24h'] if row['peak_24h'] > 0 else 0,
            axis=1
        )
        
        return features
    
    def prepare_training_data(self, df: pd.DataFrame, target_field: str):
        """
        å‡†å¤‡è®­ç»ƒæ•°æ®
        
        Args:
            df: ç‰¹å¾DataFrame
            target_field: ç›®æ ‡å­—æ®µå
            
        Returns:
            (X, y) ç‰¹å¾å’Œç›®æ ‡å€¼
        """
        # è¿‡æ»¤æ‰ç›®æ ‡å€¼ä¸º0æˆ–ç¼ºå¤±çš„è®°å½•
        valid_mask = (df[target_field] > 0)
        df_valid = df[valid_mask].copy()
        
        # æ ¹æ®é¢„æµ‹ç›®æ ‡é€‰æ‹©ç‰¹å¾
        if target_field == 'current_players':
            # é¢„æµ‹å½“å‰åœ¨çº¿:ä¸ä½¿ç”¨å½“å‰åœ¨çº¿æœ¬èº«
            feature_cols = ['game_age_years', 'is_free', 'price_numeric', 
                          'playtime_avg', 'playtime_median', 'playtime_price_ratio',
                          'peak_24h', 'peak_alltime', 'historical_growth']
        elif target_field == 'peak_24h':
            # é¢„æµ‹24å°æ—¶å³°å€¼:ä¸ä½¿ç”¨24å°æ—¶å³°å€¼å’Œè¡ç”Ÿç‰¹å¾
            feature_cols = ['game_age_years', 'is_free', 'price_numeric',
                          'playtime_avg', 'playtime_median', 'playtime_price_ratio',
                          'current_players', 'peak_alltime']
        elif target_field == 'peak_alltime':
            # é¢„æµ‹å†å²å³°å€¼:ä¸ä½¿ç”¨å†å²å³°å€¼å’Œè¡ç”Ÿç‰¹å¾
            feature_cols = ['game_age_years', 'is_free', 'price_numeric',
                          'playtime_avg', 'playtime_median', 'playtime_price_ratio',
                          'current_players', 'peak_24h', 'activity_ratio']
        else:
            raise ValueError(f"Unknown target field: {target_field}")
        
        X = df_valid[feature_cols].copy()
        y = df_valid[target_field].copy()
        
        return X, y, feature_cols
    
    def train_model(self, X, y, target_field: str):
        """
        è®­ç»ƒæ¨¡å‹å¹¶è¯„ä¼°
        
        Args:
            X: ç‰¹å¾
            y: ç›®æ ‡å€¼
            target_field: ç›®æ ‡å­—æ®µå
            
        Returns:
            æœ€ä½³æ¨¡å‹
        """
        print(f"\n{'='*80}")
        print(f"è®­ç»ƒ {target_field} é¢„æµ‹æ¨¡å‹")
        print(f"{'='*80}")
        print(f"è®­ç»ƒæ ·æœ¬æ•°: {len(X)}")
        print(f"ç›®æ ‡å€¼èŒƒå›´: [{y.min():.0f}, {y.max():.0f}]")
        print(f"ç›®æ ‡å€¼å‡å€¼: {y.mean():.0f}")
        print(f"ç›®æ ‡å€¼ä¸­ä½æ•°: {y.median():.0f}")
        
        # åˆ†å‰²è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        # æµ‹è¯•å¤šä¸ªæ¨¡å‹
        models = {
            'RandomForest': RandomForestRegressor(
                n_estimators=100,
                max_depth=20,
                min_samples_split=5,
                min_samples_leaf=2,
                random_state=42,
                n_jobs=-1
            ),
            'GradientBoosting': GradientBoostingRegressor(
                n_estimators=100,
                max_depth=10,
                learning_rate=0.1,
                random_state=42
            ),
            'LinearRegression': LinearRegression()
        }
        
        results = {}
        print(f"\næ¨¡å‹è¯„ä¼°:")
        print("â”€"*80)
        
        for name, model in models.items():
            # è®­ç»ƒæ¨¡å‹
            model.fit(X_train, y_train)
            
            # é¢„æµ‹
            y_pred_train = model.predict(X_train)
            y_pred_test = model.predict(X_test)
            
            # è¯„ä¼°æŒ‡æ ‡
            train_mae = mean_absolute_error(y_train, y_pred_train)
            test_mae = mean_absolute_error(y_test, y_pred_test)
            train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))
            test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))
            train_r2 = r2_score(y_train, y_pred_train)
            test_r2 = r2_score(y_test, y_pred_test)
            
            # äº¤å‰éªŒè¯
            cv_scores = cross_val_score(model, X_train, y_train, cv=5, 
                                       scoring='neg_mean_absolute_error', n_jobs=-1)
            cv_mae = -cv_scores.mean()
            
            results[name] = {
                'model': model,
                'train_mae': train_mae,
                'test_mae': test_mae,
                'train_rmse': train_rmse,
                'test_rmse': test_rmse,
                'train_r2': train_r2,
                'test_r2': test_r2,
                'cv_mae': cv_mae
            }
            
            print(f"\n{name}:")
            print(f"  è®­ç»ƒé›† MAE: {train_mae:,.0f} | RMSE: {train_rmse:,.0f} | RÂ²: {train_r2:.4f}")
            print(f"  æµ‹è¯•é›† MAE: {test_mae:,.0f} | RMSE: {test_rmse:,.0f} | RÂ²: {test_r2:.4f}")
            print(f"  äº¤å‰éªŒè¯ MAE: {cv_mae:,.0f}")
        
        # é€‰æ‹©æµ‹è¯•é›†MAEæœ€å°çš„æ¨¡å‹
        best_model_name = min(results.keys(), key=lambda k: results[k]['test_mae'])
        best_model = results[best_model_name]['model']
        
        print(f"\nâœ… æœ€ä½³æ¨¡å‹: {best_model_name}")
        print(f"   æµ‹è¯•é›† MAE: {results[best_model_name]['test_mae']:,.0f}")
        print(f"   æµ‹è¯•é›† RÂ²: {results[best_model_name]['test_r2']:.4f}")
        
        # ç‰¹å¾é‡è¦æ€§(å¦‚æœæ”¯æŒ)
        if hasattr(best_model, 'feature_importances_'):
            importances = best_model.feature_importances_
            feature_names = X.columns
            feature_importance = sorted(zip(feature_names, importances), 
                                       key=lambda x: x[1], reverse=True)
            
            print(f"\nç‰¹å¾é‡è¦æ€§ (Top 5):")
            for feat, imp in feature_importance[:5]:
                print(f"  {feat}: {imp:.4f}")
            
            self.feature_importance[target_field] = feature_importance
        
        # ä¿å­˜è®­ç»ƒç»Ÿè®¡
        self.training_stats[target_field] = {
            'model_name': best_model_name,
            'train_samples': len(X_train),
            'test_samples': len(X_test),
            'test_mae': float(results[best_model_name]['test_mae']),
            'test_rmse': float(results[best_model_name]['test_rmse']),
            'test_r2': float(results[best_model_name]['test_r2']),
            'cv_mae': float(results[best_model_name]['cv_mae']),
            'target_mean': float(y.mean()),
            'target_median': float(y.median()),
            'target_min': float(y.min()),
            'target_max': float(y.max())
        }
        
        return best_model
    
    def train_all_models(self, data_file: str):
        """
        è®­ç»ƒæ‰€æœ‰é¢„æµ‹æ¨¡å‹
        
        Args:
            data_file: æ•°æ®æ–‡ä»¶è·¯å¾„
        """
        print("="*80)
        print("åœ¨çº¿äººæ•°é¢„æµ‹æ¨¡å‹è®­ç»ƒ")
        print("="*80)
        
        # è¯»å–æ•°æ®
        print(f"\nğŸ“‚ è¯»å–æ•°æ®: {data_file}")
        df = pd.read_csv(data_file, encoding='utf-8-sig')
        print(f"   æ€»è®°å½•æ•°: {len(df)}")
        
        # æå–ç‰¹å¾
        print(f"\nğŸ”§ æå–ç‰¹å¾...")
        features_df = self.extract_features(df)
        print(f"   ç‰¹å¾ç»´åº¦: {features_df.shape}")
        
        # è®­ç»ƒä¸‰ä¸ªæ¨¡å‹
        targets = ['current_players', 'peak_24h', 'peak_alltime']
        
        for target in targets:
            X, y, feature_cols = self.prepare_training_data(features_df, target)
            
            if len(X) < 10:
                print(f"\nâš ï¸ {target}: æœ‰æ•ˆæ ·æœ¬æ•°å¤ªå°‘ ({len(X)}),è·³è¿‡")
                continue
            
            model = self.train_model(X, y, target)
            self.models[target] = {
                'model': model,
                'feature_cols': feature_cols
            }
        
        # ä¿å­˜æ¨¡å‹å’Œç»Ÿè®¡ä¿¡æ¯
        self.save_models()
        
    def save_models(self):
        """ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹"""
        script_dir = os.path.dirname(os.path.abspath(__file__))
        
        # ä¿å­˜æ¨¡å‹æ–‡ä»¶
        for target, model_info in self.models.items():
            model_path = os.path.join(script_dir, f"model_{target}.pkl")
            joblib.dump(model_info, model_path)
            print(f"\nğŸ’¾ ä¿å­˜æ¨¡å‹: {model_path}")
        
        # ä¿å­˜è®­ç»ƒç»Ÿè®¡
        stats_path = os.path.join(script_dir, "model_training_stats.json")
        with open(stats_path, 'w', encoding='utf-8') as f:
            json.dump(self.training_stats, f, indent=2, ensure_ascii=False)
        print(f"ğŸ’¾ ä¿å­˜ç»Ÿè®¡: {stats_path}")
        
        # ä¿å­˜ç‰¹å¾é‡è¦æ€§
        importance_path = os.path.join(script_dir, "feature_importance.txt")
        with open(importance_path, 'w', encoding='utf-8') as f:
            f.write("ç‰¹å¾é‡è¦æ€§åˆ†æ\n")
            f.write("="*80 + "\n\n")
            
            for target, importances in self.feature_importance.items():
                f.write(f"\n{target}:\n")
                f.write("â”€"*80 + "\n")
                for feat, imp in importances:
                    f.write(f"  {feat:30s} {imp:.6f}\n")
        
        print(f"ğŸ’¾ ä¿å­˜ç‰¹å¾é‡è¦æ€§: {importance_path}")
        
    def generate_report(self):
        """ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š"""
        script_dir = os.path.dirname(os.path.abspath(__file__))
        report_path = os.path.join(script_dir, "MODEL_TRAINING_REPORT.md")
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# åœ¨çº¿äººæ•°é¢„æµ‹æ¨¡å‹è®­ç»ƒæŠ¥å‘Š\n\n")
            f.write(f"**è®­ç»ƒæ—¶é—´:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("## ğŸ“Š æ¨¡å‹æ¦‚è§ˆ\n\n")
            f.write("| ç›®æ ‡å­—æ®µ | æ¨¡å‹ç±»å‹ | æµ‹è¯•é›†MAE | æµ‹è¯•é›†RMSE | RÂ² | è®­ç»ƒæ ·æœ¬ |\n")
            f.write("|---------|---------|-----------|-----------|-----|----------|\n")
            
            for target, stats in self.training_stats.items():
                target_cn = {
                    'current_players': 'å½“å‰åœ¨çº¿äººæ•°',
                    'peak_24h': '24å°æ—¶å³°å€¼',
                    'peak_alltime': 'å†å²æœ€é«˜åœ¨çº¿'
                }.get(target, target)
                
                f.write(f"| {target_cn} | {stats['model_name']} | "
                       f"{stats['test_mae']:,.0f} | {stats['test_rmse']:,.0f} | "
                       f"{stats['test_r2']:.4f} | {stats['train_samples']} |\n")
            
            f.write("\n## ğŸ“ˆ è¯¦ç»†ç»Ÿè®¡\n\n")
            
            for target, stats in self.training_stats.items():
                target_cn = {
                    'current_players': 'å½“å‰åœ¨çº¿äººæ•°',
                    'peak_24h': '24å°æ—¶å³°å€¼',
                    'peak_alltime': 'å†å²æœ€é«˜åœ¨çº¿'
                }.get(target, target)
                
                f.write(f"### {target_cn}\n\n")
                f.write(f"**æ¨¡å‹ç±»å‹:** {stats['model_name']}\n\n")
                f.write(f"**æ•°æ®é›†:**\n")
                f.write(f"- è®­ç»ƒæ ·æœ¬: {stats['train_samples']}\n")
                f.write(f"- æµ‹è¯•æ ·æœ¬: {stats['test_samples']}\n\n")
                
                f.write(f"**ç›®æ ‡å€¼ç»Ÿè®¡:**\n")
                f.write(f"- å‡å€¼: {stats['target_mean']:,.0f}\n")
                f.write(f"- ä¸­ä½æ•°: {stats['target_median']:,.0f}\n")
                f.write(f"- èŒƒå›´: [{stats['target_min']:,.0f}, {stats['target_max']:,.0f}]\n\n")
                
                f.write(f"**æ¨¡å‹æ€§èƒ½:**\n")
                f.write(f"- æµ‹è¯•é›†å¹³å‡ç»å¯¹è¯¯å·®(MAE): {stats['test_mae']:,.0f}\n")
                f.write(f"- æµ‹è¯•é›†å‡æ–¹æ ¹è¯¯å·®(RMSE): {stats['test_rmse']:,.0f}\n")
                f.write(f"- æµ‹è¯•é›†å†³å®šç³»æ•°(RÂ²): {stats['test_r2']:.4f}\n")
                f.write(f"- äº¤å‰éªŒè¯MAE: {stats['cv_mae']:,.0f}\n\n")
                
                # ç‰¹å¾é‡è¦æ€§
                if target in self.feature_importance:
                    f.write(f"**ç‰¹å¾é‡è¦æ€§ (Top 10):**\n\n")
                    for feat, imp in self.feature_importance[target][:10]:
                        f.write(f"- {feat}: {imp:.6f}\n")
                    f.write("\n")
            
            f.write("## ğŸ’¡ ä½¿ç”¨è¯´æ˜\n\n")
            f.write("æ¨¡å‹å·²ä¿å­˜ä¸ºä»¥ä¸‹æ–‡ä»¶:\n")
            f.write("- `model_current_players.pkl` - å½“å‰åœ¨çº¿äººæ•°é¢„æµ‹æ¨¡å‹\n")
            f.write("- `model_peak_24h.pkl` - 24å°æ—¶å³°å€¼é¢„æµ‹æ¨¡å‹\n")
            f.write("- `model_peak_alltime.pkl` - å†å²æœ€é«˜åœ¨çº¿é¢„æµ‹æ¨¡å‹\n\n")
            
            f.write("åœ¨ `data_cleaner.py` ä¸­ä½¿ç”¨:\n")
            f.write("```python\n")
            f.write("import joblib\n")
            f.write("model_info = joblib.load('model_current_players.pkl')\n")
            f.write("model = model_info['model']\n")
            f.write("predictions = model.predict(X)\n")
            f.write("```\n")
        
        print(f"\nğŸ“„ ç”ŸæˆæŠ¥å‘Š: {report_path}")


def main():
    """ä¸»å‡½æ•°"""
    script_dir = os.path.dirname(os.path.abspath(__file__))
    data_file = os.path.join(script_dir, "Source data.csv")
    
    if not os.path.exists(data_file):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶")
        print(f"   æœŸæœ›è·¯å¾„: {data_file}")
        return
    
    # åˆ›å»ºé¢„æµ‹å™¨å¹¶è®­ç»ƒ
    predictor = PlayerCountPredictor()
    predictor.train_all_models(data_file)
    
    # ç”ŸæˆæŠ¥å‘Š
    predictor.generate_report()
    
    print("\n" + "="*80)
    print("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ!")
    print("="*80)
    print("\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
    print("   - model_current_players.pkl")
    print("   - model_peak_24h.pkl")
    print("   - model_peak_alltime.pkl")
    print("   - model_training_stats.json")
    print("   - feature_importance.txt")
    print("   - MODEL_TRAINING_REPORT.md")
    print("\nä¸‹ä¸€æ­¥: åœ¨ data_cleaner.py ä¸­é›†æˆè¿™äº›æ¨¡å‹")


if __name__ == "__main__":
    main()
